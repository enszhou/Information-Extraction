{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T12:36:22.475769Z",
     "start_time": "2020-12-21T12:36:18.053953Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import string\n",
    "import gensim\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T02:16:51.119488Z",
     "start_time": "2020-12-22T02:16:51.106911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6400"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_letters = string.punctuation\n",
    "del_tran_table = str.maketrans(del_letters, \" \" * len(del_letters))\n",
    "\n",
    "relations = ['Cause-Effect', 'Component-Whole', 'Entity-Destination', 'Product-Producer', 'Entity-Origin',\n",
    "             'Member-Collection', 'Message-Topic', 'Content-Container', 'Instrument-Agency', 'Other']\n",
    "\n",
    "\n",
    "def preprocess(sentence):\n",
    "    sentence = sentence.translate(del_tran_table)\n",
    "    tokens = nltk.tokenize.word_tokenize(sentence)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "dataset_dir = os.path.join(\"..\", \"dataset\", \"\")\n",
    "train_path = os.path.join(dataset_dir, \"train.txt\")\n",
    "\n",
    "# sentences = list()\n",
    "texts = list()\n",
    "labels = list()\n",
    "with open(train_path) as fp:\n",
    "    while True:\n",
    "        line = fp.readline()\n",
    "        label = fp.readline()\n",
    "        if not line or not label:\n",
    "            break\n",
    "        texts.append(line.split(\" \", 1)[1])\n",
    "#         sentence = preprocess(line.split(\" \", 1)[1])\n",
    "#         sentences.append(sentence)\n",
    "#         if len(sentence) > max_len:\n",
    "#             max_len = len(sentence)\n",
    "        labels.append(label.split('(')[0])\n",
    "num_sample = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-22T03:54:22.611998Z",
     "start_time": "2020-12-22T03:54:22.441977Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,    2, 1875, 1876],\n",
       "       [   0,    0,    0, ...,    2,    3, 1877],\n",
       "       [   0,    0,    0, ..., 1654,  849,  850],\n",
       "       ...,\n",
       "       [   0,    0,    0, ...,    5,  395,  405],\n",
       "       [   0,    0,    0, ...,    1,  779,  276],\n",
       "       [   0,    0,    0, ...,  536,   15, 3990]], dtype=int32)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 10000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sentences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "maxlen = max(map(len, sentences))\n",
    "\n",
    "data = tf.keras.preprocessing.sequence.pad_sequences(sentences, maxlen=maxlen)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:53:08.891210Z",
     "start_time": "2020-12-21T14:53:08.866177Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "# model = gensim.models.Word2Vec(sentences, min_count=1)\n",
    "model = fasttext.load_model(os.path.join('..', 'res', 'dbpedia.ftz'))\n",
    "vec_len = model.get_dimension()\n",
    "\n",
    "\n",
    "def get_vec(word):\n",
    "    return model[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:53:56.503688Z",
     "start_time": "2020-12-21T14:53:55.068218Z"
    }
   },
   "outputs": [],
   "source": [
    "X = list()\n",
    "seq_lens = list()\n",
    "seq_masks = list()\n",
    "for sentence in sentences:\n",
    "    seq = list()\n",
    "    sentence_len = len(sentence)\n",
    "    seq_lens.append(sentence_len)\n",
    "    seq_masks.append(sentence_len * [True] + (max_len-sentence_len) * [False])\n",
    "    for word in sentence:\n",
    "        word_vec = get_vec(word)\n",
    "        seq.append(word_vec)\n",
    "    for i in range(max_len-sentence_len):\n",
    "        seq.append([0] * vec_len)\n",
    "    X.append(seq)\n",
    "X = np.asarray(X)\n",
    "seq_lens = np.asarray(seq_lens)\n",
    "seq_masks = np.asarray(seq_masks)\n",
    "\n",
    "\n",
    "Y = list(map(relations.index, labels))\n",
    "Y = np.eye(len(relations))[Y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:53:14.980193Z",
     "start_time": "2020-12-21T14:53:14.977353Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "num_train = int(num_sample * train_ratio)\n",
    "rand_indices = np.random.permutation(np.arange(num_sample))\n",
    "indices_train = rand_indices[:num_train]\n",
    "indices_test = rand_indices[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T14:55:11.244775Z",
     "start_time": "2020-12-21T14:55:11.207929Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X[indices_train]\n",
    "X_test = X[indices_test]\n",
    "Y_train = Y[indices_train]\n",
    "Y_test = Y[indices_test]\n",
    "# seq_lens_train = seq_lens[indices_train]\n",
    "# seq_lens_test = seq_lens[indices_test]\n",
    "seq_masks_train = seq_masks[indices_train]\n",
    "seq_masks_test = seq_masks[indices_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-21T15:22:00.772524Z",
     "start_time": "2020-12-21T15:21:47.532855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 13s 82ms/step - loss: 2.2813 - accuracy: 0.1464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4fc8231310>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tf.keras.Input(shape=(max_len, vec_len))\n",
    "x = tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2)(\n",
    "    inputs=inputs,)\n",
    "outputs = tf.keras.layers.Dense(len(relations), activation='softmax')(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 302.4,
   "position": {
    "height": "324.4px",
    "left": "1590px",
    "right": "20px",
    "top": "138px",
    "width": "421px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
